{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azureml\n",
    "# !pip install azureml-core --user\n",
    "# !pip install azureml.widgets\n",
    "#!pip install azureml.dataprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For automatic reloading of modified libraries\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Regular python libraries\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import json\n",
    "import statistics\n",
    "\n",
    "import torch\n",
    "\n",
    "# AzureML libraries\n",
    "import azureml\n",
    "import azureml.core\n",
    "from azureml.core import Experiment, Workspace, Datastore, ScriptRunConfig\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.container_registry import ContainerRegistry\n",
    "from azureml.core.runconfig import MpiConfiguration, RunConfiguration, DEFAULT_GPU_IMAGE\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Check core SDK version number\n",
    "#print(\"SDK version:\", azureml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:\t\tSubstrateIntelligenceNLR-WS2\n",
      "Location:\teastus\n"
     ]
    }
   ],
   "source": [
    "subscription_id = '42ae47bd-b19b-42c1-b0b9-19fd5be9d51b'\n",
    "resource_group = 'bert-base'\n",
    "workspace_name = 'SubstrateIntelligenceNLR-WS2'\n",
    "ws = Workspace(subscription_id, resource_group, workspace_name)\n",
    "ws_details = ws.get_details()\n",
    "print('Name:\\t\\t{}\\nLocation:\\t{}'\n",
    "      .format(ws_details['name'],\n",
    "              ws_details['location']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datastore name: default\n",
      "Container name: azureml-blobstore-d6fc2475-ad02-44a7-90ff-88a2a91e66b1\n",
      "Datastore type: AzureBlob\n",
      "Workspace name: SubstrateIntelligenceNLR-WS2\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Datastore\n",
    "ds = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                             datastore_name='default',\n",
    "                                             container_name='azureml-blobstore-d6fc2475-ad02-44a7-90ff-88a2a91e66b1',\n",
    "                                             account_name='substrateintel3704284680', \n",
    "                                             account_key = 'replaceme',\n",
    "                                             create_if_not_exists=True\n",
    "                                            )\n",
    "\n",
    "print('Datastore name: ' + ds.name, \n",
    "      'Container name: ' + ds.container_name, \n",
    "      'Datastore type: ' + ds.datastore_type, \n",
    "      'Workspace name: ' + ds.workspace.name, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'currentNodeCount': 9, 'targetNodeCount': 9, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 9, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2021-01-22T10:27:14.096000+00:00', 'errors': None, 'creationTime': '2020-09-08T21:22:56.219502+00:00', 'modifiedTime': '2021-01-22T08:44:17.163555+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 9, 'maxNodeCount': 16, 'nodeIdleTimeBeforeScaleDown': 'PT1200S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC24RS_V3'}\n"
     ]
    }
   ],
   "source": [
    "gpu_cluster_name = \"sriovdedicated1\"\n",
    "gpu_compute_target = ComputeTarget(workspace=ws, name=gpu_cluster_name)\n",
    "print(gpu_compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bart seq to seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_name = 'train.py'\n",
    "codepath = '.'\n",
    "\n",
    "from azureml.core import Dataset\n",
    "from azureml.data import OutputFileDatasetConfig\n",
    "\n",
    "#create input/output datasets\n",
    "def ds_path(path):\n",
    "    try:\n",
    "        return Dataset.File.from_files(ds.path(path))\n",
    "    except Exception as e:\n",
    "        print(f'Using {path} as output')\n",
    "        return OutputFileDatasetConfig(destination=(ds, path))\n",
    "\n",
    "processes = 1\n",
    "op = 'preprocess'\n",
    "def get_args():\n",
    "    all_params_default = [\n",
    "                    '--data_path', ds_path(f'krishan/bart/cnn_dm').as_download(),\n",
    "                    '--config_path', 'config-prod.yaml',\n",
    "                    '--tmgr.gpu_batch_size_limit',8,\n",
    "                    '--dist',\n",
    "                    '--chkp.save_dir', ds_path(f'krishan/bart/ckpts/cnndm_sum').as_mount(),\n",
    "    ]\n",
    "    return all_params_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--data_path', <azureml.data.dataset_consumption_config.DatasetConsumptionConfig object at 0x000001B95B0066A0>, '--config_path', 'config-prod.yaml', '--tmgr.gpu_batch_size_limit', 8, '--dist', '--chkp.save_dir', <azureml.data.dataset_consumption_config.DatasetConsumptionConfig object at 0x000001B95AFF8700>]\n"
     ]
    }
   ],
   "source": [
    "print(get_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "myenv = Environment(name=\"myenv\")\n",
    "\n",
    "# Creates the environment inside a Docker container.\n",
    "myenv.docker.enabled = True\n",
    "myenv.docker.base_image = 'krishansubudhi/marlin:latest'\n",
    "myenv.python.interpreter_path = '/opt/miniconda/envs/marlin/bin/python'\n",
    "myenv.python.user_managed_dependencies = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpi = MpiConfiguration() \n",
    "mpi.process_count_per_node = 4 #NC SKU has 4 GPU's per node\n",
    "mpi.node_count = 1 #scale to the amount of nodes you'd like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted run\n"
     ]
    }
   ],
   "source": [
    "config = ScriptRunConfig(source_directory=codepath,\n",
    "                         script=script_name,\n",
    "                         arguments = get_args(),\n",
    "                         compute_target=gpu_compute_target,\n",
    "                         environment=myenv,\n",
    "                         distributed_job_config=mpi)\n",
    "\n",
    "experiment_name = 'marlin_bart_seq2seqft'\n",
    "experiment = Experiment(ws, name=experiment_name)\n",
    "\n",
    "run = experiment.submit(config)\n",
    "\n",
    "run.tag('nodes', f'{mpi.node_count}')\n",
    "print(\"Submitted run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>marlin_bart_seq2seqft</td><td>marlin_bart_seq2seqft_1611786404_8262c574</td><td>azureml.scriptrun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/experiments/marlin_bart_seq2seqft/runs/marlin_bart_seq2seqft_1611786404_8262c574?wsid=/subscriptions/42ae47bd-b19b-42c1-b0b9-19fd5be9d51b/resourcegroups/bert-base/workspaces/SubstrateIntelligenceNLR-WS2\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: marlin_bart_seq2seqft,\n",
       "Id: marlin_bart_seq2seqft_1611786404_8262c574,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Preparing)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

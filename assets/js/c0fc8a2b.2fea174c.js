(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[3937],{3905:function(e,n,t){"use strict";t.d(n,{Zo:function(){return c},kt:function(){return f}});var a=t(7294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function s(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?s(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):s(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},s=Object.keys(e);for(a=0;a<s.length;a++)t=s[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(a=0;a<s.length;a++)t=s[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var o=a.createContext({}),p=function(e){var n=a.useContext(o),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},c=function(e){var n=p(e.components);return a.createElement(o.Provider,{value:n},e.children)},d={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},u=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,s=e.originalType,o=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),u=p(t),f=r,m=u["".concat(o,".").concat(f)]||u[f]||d[f]||s;return t?a.createElement(m,i(i({ref:n},c),{},{components:t})):a.createElement(m,i({ref:n},c))}));function f(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var s=t.length,i=new Array(s);i[0]=u;var l={};for(var o in n)hasOwnProperty.call(n,o)&&(l[o]=n[o]);l.originalType=e,l.mdxType="string"==typeof e?e:r,i[1]=l;for(var p=2;p<s;p++)i[p]=t[p];return a.createElement.apply(null,i)}return a.createElement.apply(null,t)}u.displayName="MDXCreateElement"},9095:function(e,n,t){"use strict";t.r(n),t.d(n,{frontMatter:function(){return i},metadata:function(){return l},toc:function(){return o},default:function(){return c}});var a=t(2122),r=t(9756),s=(t(7294),t(3905)),i={},l={unversionedId:"examples/cifar",id:"examples/cifar",isDocsHomePage:!1,title:"CIFAR image classification",description:"In this tutorial, we will demonstrate how we can use Microsoft PyMarlin library to train an image classifier.",source:"@site/docs/examples/cifar.md",sourceDirName:"examples",slug:"/examples/cifar",permalink:"/PyMarlin/docs/examples/cifar",editUrl:"https://github.com/microsoft/PyMarlin/edit/master/website/docs/examples/cifar.md",version:"current",frontMatter:{},sidebar:"docsSidebar",previous:{title:"PyMarlin in Pictures",permalink:"/PyMarlin/docs/marlin-in-pictures"},next:{title:"Covid-19 Classification",permalink:"/PyMarlin/docs/examples/classification"}},o=[{value:"Run in Colab",id:"run-in-colab",children:[]},{value:"Step 1. Data preprocessing",id:"step-1-data-preprocessing",children:[]},{value:"Step 2. Training",id:"step-2-training",children:[{value:"Train for few steps",id:"train-for-few-steps",children:[]}]},{value:"Step 3. Saving the model",id:"step-3-saving-the-model",children:[]}],p={toc:o};function c(e){var n=e.components,i=(0,r.Z)(e,["components"]);return(0,s.kt)("wrapper",(0,a.Z)({},p,i,{components:n,mdxType:"MDXLayout"}),(0,s.kt)("p",null,"In this tutorial, we will demonstrate how we can use ",(0,s.kt)("a",{parentName:"p",href:"https://github.com/microsoft/PyMarlin"},"Microsoft PyMarlin")," library to train an image classifier."),(0,s.kt)("p",null,"This tutorial is based on official ",(0,s.kt)("a",{parentName:"p",href:"https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py"},"PyTorch blog on Training a classifier")," which trains a image classifier using CIFAR data."),(0,s.kt)("h2",{id:"run-in-colab"},"Run in ",(0,s.kt)("a",{parentName:"h2",href:"https://colab.research.google.com/github/microsoft/PyMarlin/blob/main/examples/CIFAR/CIFAR.ipynb"},"Colab")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"# !pip install pymarlin\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\n")),(0,s.kt)("h2",{id:"step-1-data-preprocessing"},"Step 1. Data preprocessing"),(0,s.kt)("p",null,"This step involves, "),(0,s.kt)("ol",null,(0,s.kt)("li",{parentName:"ol"},"Downloading data"),(0,s.kt)("li",{parentName:"ol"},"Preprocessing it "),(0,s.kt)("li",{parentName:"ol"},"Analyzing it"),(0,s.kt)("li",{parentName:"ol"},"Creating a final dataset")),(0,s.kt)("p",null,"In pymarlin, ",(0,s.kt)("strong",{parentName:"p"},"DataInteface")," and ",(0,s.kt)("strong",{parentName:"p"},"DataProcessor")," is where you implement the code related to all the steps above."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"from pymarlin.core import data_interface\nclass CifarDataProcessor(data_interface.DataProcessor):\n    def process(self):\n        transform = transforms.Compose(\n            [transforms.ToTensor(),\n             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n        trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\n        testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\n        self.datasets = {'Train': trainset, 'Test': testset}\n        return self.datasets\n\n    def analyze(self):\n        datasets = self.datasets\n        print(f'train data size = {len(datasets[\"Train\"])}')\n        print(f'val data size = {len(datasets[\"Test\"])}')\n        print('Examples')\n        sample_images = [datasets['Train'][i][0] for i in range(4)]\n        self._imshow(torchvision.utils.make_grid(sample_images))\n        \n    def _imshow(self,img):\n        img = img / 2 + 0.5     # unnormalize\n        npimg = img.numpy()\n        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n        plt.show()\n\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"dp = CifarDataProcessor()\n# process_data calls both process and analyze\ndatasets = dp.process_data()\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"Files already downloaded and verified\nFiles already downloaded and verified\ntrain data size = 50000\nval data size = 10000\nExamples\n")),(0,s.kt)("p",null,(0,s.kt)("img",{alt:"png",src:t(4599).Z})),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"class CifarDataInterface(data_interface.DataInterface):\n    \n    def __init__(self, dp:CifarDataProcessor):\n        datasets = dp.process()\n        self.train_ds = datasets['Train']\n        self.val_ds = datasets['Test']\n\n    @property\n    def classes(self):\n        return ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n    \n    def get_train_dataset(self):\n        return self.train_ds\n    \n    def get_val_dataset(self):\n        return self.val_ds \n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"di  = CifarDataInterface(dp)\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"Files already downloaded and verified\nFiles already downloaded and verified\n")),(0,s.kt)("h2",{id:"step-2-training"},"Step 2. Training"),(0,s.kt)("p",null,"We will override pymarlin's ModuleInterface and create a training recipe."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"# Actual model architecture\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"# Training recipe\nfrom pymarlin import ModuleInterface\nclass CifarModule(ModuleInterface):\n    '''\n    ModuleInterface contains instruction to create data loader , \n    defines train step, optimizer, scheduler, evaluation etc.\n    \n    Just implement the abstract function: refer docstrings.\n    '''\n    def __init__(self, data_interface):\n        super().__init__() # always initialize superclass first\n        self.data_interface = data_interface\n        \n        self.net = Net()\n        self.criterion = nn.CrossEntropyLoss()\n        self.optimizer = optim.SGD(self.net.parameters(), lr=0.001, momentum=0.9)\n        \n        self.running_loss = 0.0\n\n    def get_optimizers_schedulers(\n        self, estimated_global_steps_per_epoch: int, epochs: int\n        ):\n        return [self.optimizer], []\n\n    def get_train_dataloader(\n        self, sampler:type, batch_size:int\n        ):\n        return torch.utils.data.DataLoader(self.data_interface.get_train_dataset(), batch_size=batch_size,\n                                          shuffle=True)\n\n    def get_val_dataloaders(\n        self, sampler:torch.utils.data.Sampler, batch_size : int\n        ): \n        return torch.utils.data.DataLoader(self.data_interface.get_val_dataset(), batch_size=batch_size,\n                                         shuffle=False)\n\n    def train_step(\n        self, global_step: int, batch, device\n        ):\n        '''\n        First output should be loss. Can return multiple outputs\n        '''\n        inputs, labels = batch # output of dataloader will be input of train_step\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        outputs = self.net(inputs)\n        loss = self.criterion(outputs, labels)\n        self.running_loss += loss.item()\n        if global_step % 2000 == 0:    # print every 2000 mini-batches\n            print('[%5d] loss: %.3f' %\n                  (global_step, self.running_loss / 2000))\n            self.running_loss = 0.0\n        return loss\n\n    def val_step(self, global_step: int, batch, device) :\n        '''\n        Can return multiple outputs. First output need not be loss.\n        '''\n        images, labels = batch\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = self.net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total = labels.size(0)\n        correct = (predicted == labels).sum().item()\n        return correct, total\n\n    def on_end_val_epoch(self,\n        global_step: int,\n        *val_step_collated_outputs,\n        key='default'):\n        '''\n        callback after validation loop ends\n        '''\n        corrects, totals = val_step_collated_outputs\n        correct = sum(corrects) # list of integers\n        total= sum(totals)\n        \n        accuracy = 100 * correct / total\n        print(f'Val accuracy at step {global_step} = {accuracy}%')\n        \n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"module = CifarModule(di)\n")),(0,s.kt)("h3",{id:"train-for-few-steps"},"Train for few steps"),(0,s.kt)("p",null,"Check if the entire loop runs without error. Use ",(0,s.kt)("inlineCode",{parentName:"p"},"max_train_steps_per_epoch")," and ",(0,s.kt)("inlineCode",{parentName:"p"},"max_val_steps_per_epoch")," to stop early. Set them to ",(0,s.kt)("inlineCode",{parentName:"p"},"null")," to train on full data."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"from pymarlin.core import trainer, trainer_backend\nfrom pymarlin.utils.checkpointer.checkpoint_utils import DefaultCheckpointerArguments\nbackend = trainer_backend.SingleProcess()\nchkp_args = DefaultCheckpointerArguments(checkpoint=False)\n\nargs = trainer.TrainerArguments(\n    epochs=2,\n    max_train_steps_per_epoch = 100,\n    max_val_steps_per_epoch = 10,\n    train_batch_size=4,\n    val_batch_size=16,\n    writers=[],\n    log_level = 'DEBUG'\n)\ntr = trainer.Trainer(\n    trainer_backend = backend,\n    module = module,\n    args = args\n)\ntr.train()\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"Val accuracy at step 200 = 13.125%\n\nSystemLog: 2021-06-16 16:46:39,171:INFO : pymarlin.core.trainer : 168 : Finished training .. \n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"from pymarlin.core import trainer, trainer_backend\nfrom pymarlin.utils.checkpointer.checkpoint_utils import DefaultCheckpointerArguments\nbackend = trainer_backend.SingleProcess()\nchkp_args = DefaultCheckpointerArguments(checkpoint=False)\n\nargs = trainer.TrainerArguments(\n    epochs=2,\n    train_batch_size=4,\n    val_batch_size=16,\n    writers=['tensorboard'],\n    clip_grads=False,\n    log_level = 'INFO',\n    checkpointer_args=chkp_args\n)\n\ntr = trainer.Trainer(\n    trainer_backend = backend,\n    module = module,\n    args = args\n)\n\ntr.train()\n")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"SystemLog: 2021-06-16 16:32:04,452:INFO : pymarlin.core.trainer : 148 : Training epoch 0\n\n\n[ 2000] loss: 2.346\n[ 4000] loss: 1.818\n[ 6000] loss: 1.653\n[ 8000] loss: 1.559\n[10000] loss: 1.510\n[12000] loss: 1.444\n\nSystemLog: 2021-06-16 16:33:57,180:INFO : pymarlin.core.trainer : 154 : Validating\n\nVal accuracy at step 12500 = 48.54%\n\nSystemLog: 2021-06-16 16:34:00,718:INFO : pymarlin.core.trainer : 148 : Training epoch 1\n\n\n[14000] loss: 1.426\n[16000] loss: 1.363\n[18000] loss: 1.342\n[20000] loss: 1.314\n[22000] loss: 1.306\n[24000] loss: 1.292\n\nSystemLog: 2021-06-16 16:35:56,793:INFO : pymarlin.core.trainer : 154 : Validating\n\nVal accuracy at step 25000 = 53.07%\n\nSystemLog: 2021-06-16 16:36:00,478:INFO : pymarlin.core.trainer : 168 : Finished training .. \n")),(0,s.kt)("h2",{id:"step-3-saving-the-model"},"Step 3. Saving the model"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"PATH = './cifar_net.pth'\ntorch.save(module.net.state_dict(), PATH)\n")))}c.isMDXComponent=!0},4599:function(e,n,t){"use strict";n.Z=t.p+"assets/images/cifar-49560130e7b83b2930b444f8cd7aa5cd.png"}}]);